{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('C:\\\\Users\\\\NITJ\\Downloads\\\\mnist_train.csv\\\\mnist_train.csv', delimiter=',', dtype=int)\n",
    "X = df.iloc[:, 1:].values\n",
    "y = df.iloc[:, 0].values\n",
    "# Normalize\n",
    "X=X/25500\n",
    "X_train=X\n",
    "y_train=y\n",
    "\n",
    "df=pd.read_csv('C:\\\\Users\\\\NITJ\\Downloads\\\\mnist_test.csv\\\\mnist_test.csv', delimiter=',', dtype=int)\n",
    "X_test = df.iloc[:, 1:].values\n",
    "y_test = df.iloc[:, 0].values\n",
    "X_test=X_test/25500\n",
    "\n",
    "from keras.utils import np_utils\n",
    "dummy_y=np_utils.to_categorical(y_train)\n",
    "dummy_y_test=np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Neural network models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Neural network with 2 hidden layers\n",
    "def nn2(n1,n2,s1,s2,s3):\n",
    "    model = Sequential()\n",
    "    # Create the input layer and 1st hidden layer with n1 nodes\n",
    "    model.add(Dense(n1,kernel_initializer ='uniform', activation = s1, input_dim = 784))\n",
    "    # Create another hidden layer with n2 nodes\n",
    "    model.add(Dense(n2, activation=s2))\n",
    "    # Create an output layer, 10 nodes\n",
    "    model.add(Dense(10, activation=s3))\n",
    "    # Compile model\n",
    "    model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "    model.fit(X_train,dummy_y,batch_size = 100 ,nb_epoch=10)\n",
    "    train_accuracy = model.evaluate(X_train, dummy_y)\n",
    "    test_accuracy = model.evaluate(X_test, dummy_y_test)\n",
    "    return train_accuracy[1],test_accuracy[1]\n",
    "\n",
    "# Function for Neural network with 1 hidden layers\n",
    "def nn1(n1,s1,s2):\n",
    "    model = Sequential()\n",
    "    # Create the input layer and 1st hidden layer with n1 nodes\n",
    "    model.add(Dense(n1,kernel_initializer ='uniform', activation = s1, input_dim = 784))\n",
    "    # Create an output layer, 10 nodes\n",
    "    model.add(Dense(10, activation=s2))\n",
    "    # Compile model\n",
    "    model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "    model.fit(X_train,dummy_y,batch_size = 100 ,nb_epoch=10)\n",
    "    train_accuracy = model.evaluate(X_train, dummy_y)\n",
    "    test_accuracy = model.evaluate(X_test, dummy_y_test)\n",
    "    return train_accuracy[1],test_accuracy[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame(columns = ['nodes in H1', 'Activation func of H1','nodes in H2', 'Activation func of H2','Activation func of output layer','Training Accuracy','Testing Accuracy']) \n",
    "di=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITJ\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 2.3022 - accuracy: 0.1077\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 2.2943 - accuracy: 0.1966\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 2.2820 - accuracy: 0.2128\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 2.2581 - accuracy: 0.2684\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 2.2203 - accuracy: 0.2817\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 2.1717 - accuracy: 0.2804\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 2.1186 - accuracy: 0.2733\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 2.0676 - accuracy: 0.2683\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 2.0222 - accuracy: 0.2657\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 1.9832 - accuracy: 0.2631\n",
      "60000/60000 [==============================] - 2s 36us/step\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "Training Accuracy :  0.2640833258628845\n",
      "Testing Accuracy :  0.2623000144958496\n"
     ]
    }
   ],
   "source": [
    "# Architecture:\n",
    "# Input layer with 784 nodes\n",
    "# only one hidden layer with 1 node and activation function = sigmoid\n",
    "# Output layer with 10 nodes and activation function = sigmoid\n",
    "\n",
    "\n",
    "train_accuracy,test_accuracy = nn1(1,\"sigmoid\",\"sigmoid\")\n",
    "print(\"Training Accuracy : \",train_accuracy)\n",
    "print(\"Testing Accuracy : \",test_accuracy)\n",
    "d=d.append(pd.DataFrame({\"nodes in H1\":[1],\"Activation func of H1\":[\"sigmoid\"],\"nodes in H2\":[0],\"Activation func of H2\":[\"\"],\"Activation func of output layer\":[\"sigmoid\"],'Training Accuracy':[train_accuracy],'Testing Accuracy':[test_accuracy]} ,index=[di]))\n",
    "di=di+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITJ\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 2.3030 - accuracy: 0.1118\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 75us/step - loss: 2.2997 - accuracy: 0.1124\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 2.2970 - accuracy: 0.1124\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 2.2901 - accuracy: 0.1127\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 2.2737 - accuracy: 0.1416\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 2.2453 - accuracy: 0.1805\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 2.2076 - accuracy: 0.2448\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 2.1645 - accuracy: 0.2642\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 2.1194 - accuracy: 0.2627\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 75us/step - loss: 2.0758 - accuracy: 0.2556\n",
      "60000/60000 [==============================] - 2s 38us/step\n",
      "10000/10000 [==============================] - 0s 38us/step\n",
      "Training Accuracy :  0.25733333826065063\n",
      "Testing Accuracy :  0.25769999623298645\n"
     ]
    }
   ],
   "source": [
    "# Architecture:\n",
    "# Input layer with 784 nodes\n",
    "# 1st hidden layer with 1 nodes and activation function = sigmoid\n",
    "# 2nd hidden layer with 1 nodes and activation function = sigmoid\n",
    "# Output layer with 10 nodes and activation function = sigmoid\n",
    "\n",
    "\n",
    "\n",
    "train_accuracy,test_accuracy = nn2(1,1,\"sigmoid\",\"sigmoid\",\"sigmoid\")\n",
    "print(\"Training Accuracy : \",train_accuracy)\n",
    "print(\"Testing Accuracy : \",test_accuracy)\n",
    "d=d.append(pd.DataFrame({\"nodes in H1\":[1],\"Activation func of H1\":[\"sigmoid\"],\"nodes in H2\":[1],\"Activation func of H2\":[\"sigmoid\"],\"Activation func of output layer\":[\"sigmoid\"],'Training Accuracy':[train_accuracy],'Testing Accuracy':[test_accuracy]} ,index=[di]))\n",
    "di=di+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITJ\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 2.2914 - accuracy: 0.1648\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 2.1379 - accuracy: 0.3763\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 1.7372 - accuracy: 0.4759\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 1.4495 - accuracy: 0.5484\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 1.2738 - accuracy: 0.5984\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 1.1617 - accuracy: 0.6133\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 1.0819 - accuracy: 0.6331\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 1.0222 - accuracy: 0.6455\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.9749 - accuracy: 0.6631\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.9359 - accuracy: 0.6796\n",
      "60000/60000 [==============================] - 3s 51us/step\n",
      "10000/10000 [==============================] - 0s 46us/step\n",
      "Training Accuracy :  0.6885833144187927\n",
      "Testing Accuracy :  0.7008000016212463\n"
     ]
    }
   ],
   "source": [
    "# Architecture:\n",
    "# Input layer with 784 nodes\n",
    "# 1st hidden layer with 50 nodes and activation function = sigmoid\n",
    "# 2nd hidden layer with 5 nodes and activation function = sigmoid\n",
    "# Output layer with 10 nodes and activation function = sigmoid\n",
    "\n",
    "\n",
    "train_accuracy,test_accuracy = nn2(50,5,\"sigmoid\",\"sigmoid\",\"sigmoid\")\n",
    "print(\"Training Accuracy : \",train_accuracy)\n",
    "print(\"Testing Accuracy : \",test_accuracy)\n",
    "d=d.append(pd.DataFrame({\"nodes in H1\":[50],\"Activation func of H1\":[\"sigmoid\"],\"nodes in H2\":[5],\"Activation func of H2\":[\"sigmoid\"],\"Activation func of output layer\":[\"sigmoid\"],'Training Accuracy':[train_accuracy],'Testing Accuracy':[test_accuracy]} ,index=[di]))\n",
    "di=di+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITJ\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 2.0877 - accuracy: 0.2717\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.9457 - accuracy: 0.7219\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.5841 - accuracy: 0.8335\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.4574 - accuracy: 0.8686\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.4011 - accuracy: 0.8827\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.3714 - accuracy: 0.89090s - loss: 0.3719 - accuracy\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.3523 - accuracy: 0.8961\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.3367 - accuracy: 0.9008: 0s - loss: 0.3369 - accura\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.3243 - accuracy: 0.90451s - l - ETA: \n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.3137 - accuracy: 0.9076\n",
      "60000/60000 [==============================] - 4s 72us/step\n",
      "10000/10000 [==============================] - 1s 71us/step\n",
      "Training Accuracy :  0.9103166460990906\n",
      "Testing Accuracy :  0.9099000096321106\n"
     ]
    }
   ],
   "source": [
    "# Architecture:\n",
    "# Input layer with 784 nodes\n",
    "# 1st hidden layer with 400 nodes and activation function = sigmoid\n",
    "# 2nd hidden layer with 100 nodes and activation function = sigmoid\n",
    "# Output layer with 10 nodes and activation function = sigmoid\n",
    "\n",
    "\n",
    "\n",
    "train_accuracy,test_accuracy = nn2(400,100,\"sigmoid\",\"sigmoid\",\"sigmoid\")\n",
    "print(\"Training Accuracy : \",train_accuracy)\n",
    "print(\"Testing Accuracy : \",test_accuracy)\n",
    "d=d.append(pd.DataFrame({\"nodes in H1\":[400],\"Activation func of H1\":[\"sigmoid\"],\"nodes in H2\":[100],\"Activation func of H2\":[\"sigmoid\"],\"Activation func of output layer\":[\"sigmoid\"],'Training Accuracy':[train_accuracy],'Testing Accuracy':[test_accuracy]} ,index=[di]))\n",
    "di=di+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITJ\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 16s 272us/step - loss: 2.3031 - accuracy: 0.1102\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 16s 268us/step - loss: 2.3022 - accuracy: 0.0992\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 16s 264us/step - loss: 2.3022 - accuracy: 0.0996\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 16s 266us/step - loss: 2.1862 - accuracy: 0.1215\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 16s 266us/step - loss: 1.2300 - accuracy: 0.5311\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 17s 278us/step - loss: 0.7146 - accuracy: 0.7566\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 16s 268us/step - loss: 0.5501 - accuracy: 0.8231\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 16s 263us/step - loss: 0.4604 - accuracy: 0.8593\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 16s 269us/step - loss: 0.4176 - accuracy: 0.8740s - loss: 0\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 16s 270us/step - loss: 0.3969 - accuracy: 0.8812\n",
      "60000/60000 [==============================] - 8s 140us/step\n",
      "10000/10000 [==============================] - 1s 137us/step\n",
      "Training Accuracy :  0.8827499747276306\n",
      "Testing Accuracy :  0.8873000144958496\n"
     ]
    }
   ],
   "source": [
    "# Architecture:\n",
    "# Input layer with 784 nodes\n",
    "# 1st hidden layer with 700 nodes and activation function = sigmoid\n",
    "# 2nd hidden layer with 700 nodes and activation function = sigmoid\n",
    "# Output layer with 10 nodes and activation function = sigmoid\n",
    "\n",
    "\n",
    "\n",
    "train_accuracy,test_accuracy = nn2(700,700,\"sigmoid\",\"sigmoid\",\"sigmoid\")\n",
    "print(\"Training Accuracy : \",train_accuracy)\n",
    "print(\"Testing Accuracy : \",test_accuracy)\n",
    "d=d.append(pd.DataFrame({\"nodes in H1\":[700],\"Activation func of H1\":[\"sigmoid\"],\"nodes in H2\":[700],\"Activation func of H2\":[\"sigmoid\"],\"Activation func of output layer\":[\"sigmoid\"],'Training Accuracy':[train_accuracy],'Testing Accuracy':[test_accuracy]} ,index=[di]))\n",
    "di=di+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITJ\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 92us/step - loss: 2.3019 - accuracy: 0.1114\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 2.3013 - accuracy: 0.1124\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 2.3012 - accuracy: 0.1124\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 2.3012 - accuracy: 0.1124\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 2.3012 - accuracy: 0.1124\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 2.3012 - accuracy: 0.1124\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 2.3012 - accuracy: 0.1124\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 2.3012 - accuracy: 0.1124\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 2.3012 - accuracy: 0.1124\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 2.3012 - accuracy: 0.1124\n",
      "60000/60000 [==============================] - 2s 36us/step\n",
      "10000/10000 [==============================] - 0s 35us/step\n",
      "Training Accuracy :  0.11236666887998581\n",
      "Testing Accuracy :  0.11349999904632568\n"
     ]
    }
   ],
   "source": [
    "# Architecture:\n",
    "# Input layer with 784 nodes\n",
    "# only one hidden layer with 1 node and activation function = relu\n",
    "# Output layer with 10 nodes and activation function = sigmoid\n",
    "\n",
    "\n",
    "\n",
    "train_accuracy,test_accuracy = nn1(1,\"relu\",\"sigmoid\")\n",
    "print(\"Training Accuracy : \",train_accuracy)\n",
    "print(\"Testing Accuracy : \",test_accuracy)\n",
    "d=d.append(pd.DataFrame({\"nodes in H1\":[1],\"Activation func of H1\":[\"relu\"],\"nodes in H2\":[0],\"Activation func of H2\":[\"\"],\"Activation func of output layer\":[\"sigmoid\"],'Training Accuracy':[train_accuracy],'Testing Accuracy':[test_accuracy]} ,index=[di]))\n",
    "di=di+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITJ\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 2.3019 - accuracy: 0.1118\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 2.3013 - accuracy: 0.1124\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 2.3012 - accuracy: 0.1124\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 2.3012 - accuracy: 0.1124\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 2.3012 - accuracy: 0.1124\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 75us/step - loss: 2.3012 - accuracy: 0.1124\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 2.3012 - accuracy: 0.1124\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 2.3012 - accuracy: 0.1124\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 2.3012 - accuracy: 0.1124\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 2.3012 - accuracy: 0.1124\n",
      "60000/60000 [==============================] - 2s 37us/step\n",
      "10000/10000 [==============================] - 0s 35us/step\n",
      "Training Accuracy :  0.11236666887998581\n",
      "Testing Accuracy :  0.11349999904632568\n"
     ]
    }
   ],
   "source": [
    "# Architecture:\n",
    "# Input layer with 784 nodes\n",
    "# 1st hidden layer with 1 nodes and activation function = relu\n",
    "# 2nd hidden layer with 1 nodes and activation function = relu\n",
    "# Output layer with 10 nodes and activation function = sigmoid\n",
    "\n",
    "\n",
    "\n",
    "train_accuracy,test_accuracy = nn2(1,1,\"relu\",\"relu\",\"sigmoid\")\n",
    "print(\"Training Accuracy : \",train_accuracy)\n",
    "print(\"Testing Accuracy : \",test_accuracy)\n",
    "d=d.append(pd.DataFrame({\"nodes in H1\":[1],\"Activation func of H1\":[\"relu\"],\"nodes in H2\":[1],\"Activation func of H2\":[\"relu\"],\"Activation func of output layer\":[\"sigmoid\"],'Training Accuracy':[train_accuracy],'Testing Accuracy':[test_accuracy]} ,index=[di]))\n",
    "di=di+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITJ\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 1.9067 - accuracy: 0.2398\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 1.0314 - accuracy: 0.6496\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.7359 - accuracy: 0.7643\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.6364 - accuracy: 0.8013\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.5742 - accuracy: 0.8260\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.5277 - accuracy: 0.8427\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.4914 - accuracy: 0.8550\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.4627 - accuracy: 0.8651\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.4390 - accuracy: 0.8717\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.4204 - accuracy: 0.8773\n",
      "60000/60000 [==============================] - 4s 69us/step\n",
      "10000/10000 [==============================] - 1s 53us/step\n",
      "Training Accuracy :  0.8813666701316833\n",
      "Testing Accuracy :  0.8848999738693237\n"
     ]
    }
   ],
   "source": [
    "# Architecture:\n",
    "# Input layer with 784 nodes\n",
    "# 1st hidden layer with 50 nodes and activation function = relu\n",
    "# 2nd hidden layer with 5 nodes and activation function = relu\n",
    "# Output layer with 10 nodes and activation function = sigmoid\n",
    "\n",
    "\n",
    "\n",
    "train_accuracy,test_accuracy = nn2(50,5,\"relu\",\"relu\",\"sigmoid\")\n",
    "print(\"Training Accuracy : \",train_accuracy)\n",
    "print(\"Testing Accuracy : \",test_accuracy)\n",
    "d=d.append(pd.DataFrame({\"nodes in H1\":[50],\"Activation func of H1\":[\"relu\"],\"nodes in H2\":[5],\"Activation func of H2\":[\"relu\"],\"Activation func of output layer\":[\"sigmoid\"],'Training Accuracy':[train_accuracy],'Testing Accuracy':[test_accuracy]} ,index=[di]))\n",
    "di=di+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITJ\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.7680 - accuracy: 0.7950\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.3292 - accuracy: 0.9050\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 9s 144us/step - loss: 0.2834 - accuracy: 0.91720s - loss: 0.2837 - accuracy: 0.91\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.2527 - accuracy: 0.9256 ETA: 1s - loss: - ETA: 0s - loss: 0.2532  - 9s 145us/step - loss: 0.2525 - accuracy: 0.9256\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.2269 - accuracy: 0.9336\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.2020 - accuracy: 0.94140s - loss: 0.2031 - \n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 9s 144us/step - loss: 0.1817 - accuracy: 0.9466\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.1618 - accuracy: 0.95231s - loss: 0.1621  -\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 9s 144us/step - loss: 0.1452 - accuracy: 0.9571\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 9s 144us/step - loss: 0.1315 - accuracy: 0.9617\n",
      "60000/60000 [==============================] - 5s 89us/step\n",
      "10000/10000 [==============================] - 1s 85us/step\n",
      "Training Accuracy :  0.9656500220298767\n",
      "Testing Accuracy :  0.9613000154495239\n"
     ]
    }
   ],
   "source": [
    "# Architecture:\n",
    "# Input layer with 784 nodes\n",
    "# 1st hidden layer with 400 nodes and activation function = relu\n",
    "# 2nd hidden layer with 100 nodes and activation function = relu\n",
    "# Output layer with 10 nodes and activation function = sigmoid\n",
    "\n",
    "\n",
    "\n",
    "train_accuracy,test_accuracy = nn2(400,100,\"relu\",\"relu\",\"sigmoid\")\n",
    "print(\"Training Accuracy : \",train_accuracy)\n",
    "print(\"Testing Accuracy : \",test_accuracy)\n",
    "d=d.append(pd.DataFrame({\"nodes in H1\":[400],\"Activation func of H1\":[\"relu\"],\"nodes in H2\":[100],\"Activation func of H2\":[\"relu\"],\"Activation func of output layer\":[\"sigmoid\"],'Training Accuracy':[train_accuracy],'Testing Accuracy':[test_accuracy]} ,index=[di]))\n",
    "di=di+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITJ\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 18s 297us/step - loss: 0.5485 - accuracy: 0.8474s - loss: 0.5489 - accuracy: 0.84\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 17s 288us/step - loss: 0.2738 - accuracy: 0.9201\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 17s 287us/step - loss: 0.2063 - accuracy: 0.9391\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 17s 287us/step - loss: 0.1554 - accuracy: 0.9544\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 17s 289us/step - loss: 0.1221 - accuracy: 0.9639\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 17s 289us/step - loss: 0.0987 - accuracy: 0.9704\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 17s 287us/step - loss: 0.0817 - accuracy: 0.9748\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 17s 288us/step - loss: 0.0683 - accuracy: 0.9791\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 17s 289us/step - loss: 0.0570 - accuracy: 0.9829\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 17s 290us/step - loss: 0.0483 - accuracy: 0.9852A: 3s - loss: 0.049\n",
      "60000/60000 [==============================] - 13s 219us/step\n",
      "10000/10000 [==============================] - 2s 224us/step\n",
      "Training Accuracy :  0.9897333383560181\n",
      "Testing Accuracy :  0.9779999852180481\n"
     ]
    }
   ],
   "source": [
    "# Architecture:\n",
    "# Input layer with 784 nodes\n",
    "# 1st hidden layer with 700 nodes and activation function = relu\n",
    "# 2nd hidden layer with 700 nodes and activation function = relu\n",
    "# Output layer with 10 nodes and activation function = sigmoid\n",
    "\n",
    "\n",
    "\n",
    "train_accuracy,test_accuracy = nn2(700,700,\"relu\",\"relu\",\"sigmoid\")\n",
    "print(\"Training Accuracy : \",train_accuracy)\n",
    "print(\"Testing Accuracy : \",test_accuracy)\n",
    "d=d.append(pd.DataFrame({\"nodes in H1\":[700],\"Activation func of H1\":[\"relu\"],\"nodes in H2\":[700],\"Activation func of H2\":[\"relu\"],\"Activation func of output layer\":[\"sigmoid\"],'Training Accuracy':[train_accuracy],'Testing Accuracy':[test_accuracy]} ,index=[di]))\n",
    "di=di+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITJ\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: nan - accuracy: 0.0987\n",
      "60000/60000 [==============================] - 2s 36us/step\n",
      "10000/10000 [==============================] - 0s 36us/step\n",
      "Training Accuracy :  0.09871666878461838\n",
      "Testing Accuracy :  0.09799999743700027\n"
     ]
    }
   ],
   "source": [
    "# Architecture:\n",
    "# Input layer with 784 nodes\n",
    "# only one hidden layer with 1 node and activation function = relu\n",
    "# Output layer with 10 nodes and activation function = relu\n",
    "\n",
    "\n",
    "\n",
    "train_accuracy,test_accuracy = nn1(1,\"relu\",\"relu\")\n",
    "print(\"Training Accuracy : \",train_accuracy)\n",
    "print(\"Testing Accuracy : \",test_accuracy)\n",
    "d=d.append(pd.DataFrame({\"nodes in H1\":[1],\"Activation func of H1\":[\"relu\"],\"nodes in H2\":[0],\"Activation func of H2\":[\"\"],\"Activation func of output layer\":[\"relu\"],'Training Accuracy':[train_accuracy],'Testing Accuracy':[test_accuracy]} ,index=[di]))\n",
    "di=di+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITJ\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 4s 75us/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 75us/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: nan - accuracy: 0.0987\n",
      "60000/60000 [==============================] - 2s 37us/step\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "Training Accuracy :  0.09871666878461838\n",
      "Testing Accuracy :  0.09799999743700027\n"
     ]
    }
   ],
   "source": [
    "# Architecture:\n",
    "# Input layer with 784 nodes\n",
    "# 1st hidden layer with 1 nodes and activation function = relu\n",
    "# 2nd hidden layer with 1 nodes and activation function = relu\n",
    "# Output layer with 10 nodes and activation function = relu\n",
    "\n",
    "\n",
    "\n",
    "train_accuracy,test_accuracy = nn2(1,1,\"relu\",\"relu\",\"relu\")\n",
    "print(\"Training Accuracy : \",train_accuracy)\n",
    "print(\"Testing Accuracy : \",test_accuracy)\n",
    "d=d.append(pd.DataFrame({\"nodes in H1\":[1],\"Activation func of H1\":[\"relu\"],\"nodes in H2\":[1],\"Activation func of H2\":[\"relu\"],\"Activation func of output layer\":[\"relu\"],'Training Accuracy':[train_accuracy],'Testing Accuracy':[test_accuracy]} ,index=[di]))\n",
    "di=di+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITJ\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: nan - accuracy: 0.0988\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: nan - accuracy: 0.0987: 0s - loss: nan - accuracy: 0.0\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: nan - accuracy: 0.0987\n",
      "60000/60000 [==============================] - 4s 70us/step\n",
      "10000/10000 [==============================] - 1s 76us/step\n",
      "Training Accuracy :  0.09871666878461838\n",
      "Testing Accuracy :  0.09799999743700027\n"
     ]
    }
   ],
   "source": [
    "# Architecture:\n",
    "# Input layer with 784 nodes\n",
    "# 1st hidden layer with 50 nodes and activation function = relu\n",
    "# 2nd hidden layer with 5 nodes and activation function = relu\n",
    "# Output layer with 10 nodes and activation function = relu\n",
    "\n",
    "\n",
    "\n",
    "train_accuracy,test_accuracy = nn2(50,5,\"relu\",\"relu\",\"relu\")\n",
    "print(\"Training Accuracy : \",train_accuracy)\n",
    "print(\"Testing Accuracy : \",test_accuracy)\n",
    "d=d.append(pd.DataFrame({\"nodes in H1\":[50],\"Activation func of H1\":[\"relu\"],\"nodes in H2\":[5],\"Activation func of H2\":[\"relu\"],\"Activation func of output layer\":[\"relu\"],'Training Accuracy':[train_accuracy],'Testing Accuracy':[test_accuracy]} ,index=[di]))\n",
    "di=di+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITJ\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: nan - accuracy: 0.1519 1s - loss: nan -\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 9s 144us/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: nan - accuracy: 0.0987A: 3s - loss: nan \n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: nan - accuracy: 0.0987 6s - loss: \n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: nan - accuracy: 0.0987ETA: 1s - loss: na\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: nan - accuracy: 0.0987 7s - loss: nan - ETA: 4s - loss: nan -  - ETA: 0s - loss: nan -\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: nan - accuracy: 0.0987 3s - loss: nan \n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: nan - accuracy: 0.0987 9s - loss - ETA: 7s - loss: nan - accura - ETA: 6s \n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: nan - accuracy: 0.0987\n",
      "60000/60000 [==============================] - 5s 90us/step\n",
      "10000/10000 [==============================] - 1s 92us/step\n",
      "Training Accuracy :  0.09871666878461838\n",
      "Testing Accuracy :  0.09799999743700027\n"
     ]
    }
   ],
   "source": [
    "# Architecture:\n",
    "# Input layer with 784 nodes\n",
    "# 1st hidden layer with 400 nodes and activation function = relu\n",
    "# 2nd hidden layer with 100 nodes and activation function = relu\n",
    "# Output layer with 10 nodes and activation function = relu\n",
    "\n",
    "\n",
    "\n",
    "train_accuracy,test_accuracy = nn2(400,100,\"relu\",\"relu\",\"relu\")\n",
    "print(\"Training Accuracy : \",train_accuracy)\n",
    "print(\"Testing Accuracy : \",test_accuracy)\n",
    "d=d.append(pd.DataFrame({\"nodes in H1\":[400],\"Activation func of H1\":[\"relu\"],\"nodes in H2\":[100],\"Activation func of H2\":[\"relu\"],\"Activation func of output layer\":[\"relu\"],'Training Accuracy':[train_accuracy],'Testing Accuracy':[test_accuracy]} ,index=[di]))\n",
    "di=di+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITJ\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 18s 294us/step - loss: nan - accuracy: 0.1135\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 17s 285us/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 17s 286us/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 17s 285us/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 17s 284us/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 17s 284us/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 17s 286us/step - loss: nan - accuracy: 0.09871s - \n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 17s 284us/step - loss: nan - accuracy: 0.09871s - loss: n\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 17s 285us/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 17s 286us/step - loss: nan - accuracy: 0.0987\n",
      "60000/60000 [==============================] - 11s 178us/step\n",
      "10000/10000 [==============================] - 2s 171us/step\n",
      "Training Accuracy :  0.09871666878461838\n",
      "Testing Accuracy :  0.09799999743700027\n"
     ]
    }
   ],
   "source": [
    "# Architecture:\n",
    "# Input layer with 784 nodes\n",
    "# 1st hidden layer with 700 nodes and activation function = relu\n",
    "# 2nd hidden layer with 700 nodes and activation function = relu\n",
    "# Output layer with 10 nodes and activation function = relu\n",
    "\n",
    "\n",
    "\n",
    "train_accuracy,test_accuracy = nn2(700,700,\"relu\",\"relu\",\"relu\")\n",
    "print(\"Training Accuracy : \",train_accuracy)\n",
    "print(\"Testing Accuracy : \",test_accuracy)\n",
    "d=d.append(pd.DataFrame({\"nodes in H1\":[700],\"Activation func of H1\":[\"relu\"],\"nodes in H2\":[700],\"Activation func of H2\":[\"relu\"],\"Activation func of output layer\":[\"relu\"],'Training Accuracy':[train_accuracy],'Testing Accuracy':[test_accuracy]} ,index=[di]))\n",
    "di=di+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITJ\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 2.3016 - accuracy: 0.1113\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 2.3013 - accuracy: 0.1124\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 2.3013 - accuracy: 0.1124\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 2.3013 - accuracy: 0.1124\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 2.3013 - accuracy: 0.1124\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 2.3013 - accuracy: 0.1124\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 2.3013 - accuracy: 0.1124\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 2.3013 - accuracy: 0.1124\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 2.3013 - accuracy: 0.1124\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 2.3013 - accuracy: 0.1124\n",
      "60000/60000 [==============================] - 2s 39us/step\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "Training Accuracy :  0.11236666887998581\n",
      "Testing Accuracy :  0.11349999904632568\n"
     ]
    }
   ],
   "source": [
    "# Architecture:\n",
    "# Input layer with 784 nodes\n",
    "# only one hidden layer with 1 node and activation function = relu\n",
    "# Output layer with 10 nodes and activation function = softmax\n",
    "\n",
    "\n",
    "\n",
    "train_accuracy,test_accuracy = nn1(1,\"relu\",\"softmax\")\n",
    "print(\"Training Accuracy : \",train_accuracy)\n",
    "print(\"Testing Accuracy : \",test_accuracy)\n",
    "d=d.append(pd.DataFrame({\"nodes in H1\":[1],\"Activation func of H1\":[\"relu\"],\"nodes in H2\":[0],\"Activation func of H2\":[\"\"],\"Activation func of output layer\":[\"softmax\"],'Training Accuracy':[train_accuracy],'Testing Accuracy':[test_accuracy]} ,index=[di]))\n",
    "di=di+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITJ\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 2.2607 - accuracy: 0.1460\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 2.0449 - accuracy: 0.2116\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 1.8897 - accuracy: 0.2587\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 1.8082 - accuracy: 0.2863\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 1.7593 - accuracy: 0.3007\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 1.7272 - accuracy: 0.3093\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 1.7048 - accuracy: 0.3172\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 1.6883 - accuracy: 0.3239\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 1.6757 - accuracy: 0.3357\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 1.6657 - accuracy: 0.3399\n",
      "60000/60000 [==============================] - 2s 38us/step\n",
      "10000/10000 [==============================] - 0s 38us/step\n",
      "Training Accuracy :  0.3385166525840759\n",
      "Testing Accuracy :  0.33899998664855957\n"
     ]
    }
   ],
   "source": [
    "# Architecture:\n",
    "# Input layer with 784 nodes\n",
    "# 1st hidden layer with 1 nodes and activation function = relu\n",
    "# 2nd hidden layer with 1 nodes and activation function = relu\n",
    "# Output layer with 10 nodes and activation function = softmax\n",
    "\n",
    "\n",
    "\n",
    "train_accuracy,test_accuracy = nn2(1,1,\"relu\",\"relu\",\"softmax\")\n",
    "print(\"Training Accuracy : \",train_accuracy)\n",
    "print(\"Testing Accuracy : \",test_accuracy)\n",
    "d=d.append(pd.DataFrame({\"nodes in H1\":[1],\"Activation func of H1\":[\"relu\"],\"nodes in H2\":[1],\"Activation func of H2\":[\"relu\"],\"Activation func of output layer\":[\"softmax\"],'Training Accuracy':[train_accuracy],'Testing Accuracy':[test_accuracy]} ,index=[di]))\n",
    "di=di+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITJ\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 1.6829 - accuracy: 0.4723\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.8509 - accuracy: 0.7301\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.6809 - accuracy: 0.7860\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.6113 - accuracy: 0.8119\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.5636 - accuracy: 0.8307\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.5265 - accuracy: 0.8453\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.4970 - accuracy: 0.8549\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.4729 - accuracy: 0.8633\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.4512 - accuracy: 0.8706\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.4322 - accuracy: 0.8758\n",
      "60000/60000 [==============================] - 4s 67us/step\n",
      "10000/10000 [==============================] - 1s 66us/step\n",
      "Training Accuracy :  0.8770333528518677\n",
      "Testing Accuracy :  0.8741999864578247\n"
     ]
    }
   ],
   "source": [
    "# Architecture:\n",
    "# Input layer with 784 nodes\n",
    "# 1st hidden layer with 50 nodes and activation function = relu\n",
    "# 2nd hidden layer with 5 nodes and activation function = relu\n",
    "# Output layer with 10 nodes and activation function = softmax\n",
    "\n",
    "\n",
    "\n",
    "train_accuracy,test_accuracy = nn2(50,5,\"relu\",\"relu\",\"softmax\")\n",
    "print(\"Training Accuracy : \",train_accuracy)\n",
    "print(\"Testing Accuracy : \",test_accuracy)\n",
    "d=d.append(pd.DataFrame({\"nodes in H1\":[50],\"Activation func of H1\":[\"relu\"],\"nodes in H2\":[5],\"Activation func of H2\":[\"relu\"],\"Activation func of output layer\":[\"softmax\"],'Training Accuracy':[train_accuracy],'Testing Accuracy':[test_accuracy]} ,index=[di]))\n",
    "di=di+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITJ\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.6713 - accuracy: 0.8140\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.2956 - accuracy: 0.9139\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.2425 - accuracy: 0.9293\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.2028 - accuracy: 0.9399\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.1721 - accuracy: 0.9498\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.1472 - accuracy: 0.9567\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.1276 - accuracy: 0.9620\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.1106 - accuracy: 0.9677\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.0973 - accuracy: 0.9704\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 0.0861 - accuracy: 0.9744\n",
      "60000/60000 [==============================] - 6s 92us/step\n",
      "10000/10000 [==============================] - 1s 91us/step\n",
      "Training Accuracy :  0.9778333306312561\n",
      "Testing Accuracy :  0.9703999757766724\n"
     ]
    }
   ],
   "source": [
    "# Architecture:\n",
    "# Input layer with 784 nodes\n",
    "# 1st hidden layer with 400 nodes and activation function = relu\n",
    "# 2nd hidden layer with 100 nodes and activation function = relu\n",
    "# Output layer with 10 nodes and activation function = softmax\n",
    "\n",
    "\n",
    "\n",
    "train_accuracy,test_accuracy = nn2(400,100,\"relu\",\"relu\",\"softmax\")\n",
    "print(\"Training Accuracy : \",train_accuracy)\n",
    "print(\"Testing Accuracy : \",test_accuracy)\n",
    "d=d.append(pd.DataFrame({\"nodes in H1\":[400],\"Activation func of H1\":[\"relu\"],\"nodes in H2\":[100],\"Activation func of H2\":[\"relu\"],\"Activation func of output layer\":[\"softmax\"],'Training Accuracy':[train_accuracy],'Testing Accuracy':[test_accuracy]} ,index=[di]))\n",
    "di=di+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITJ\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 17s 287us/step - loss: 0.5106 - accuracy: 0.8554\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 17s 279us/step - loss: 0.2322 - accuracy: 0.9311\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 16s 272us/step - loss: 0.1649 - accuracy: 0.9509\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 16s 275us/step - loss: 0.1260 - accuracy: 0.9622\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 16s 274us/step - loss: 0.0974 - accuracy: 0.9707\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 16s 270us/step - loss: 0.0789 - accuracy: 0.9760\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 16s 273us/step - loss: 0.0637 - accuracy: 0.9807\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 16s 273us/step - loss: 0.0529 - accuracy: 0.9838\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 16s 271us/step - loss: 0.0444 - accuracy: 0.9860\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 17s 285us/step - loss: 0.0357 - accuracy: 0.9888\n",
      "60000/60000 [==============================] - 12s 195us/step\n",
      "10000/10000 [==============================] - 2s 201us/step\n",
      "Training Accuracy :  0.9895833134651184\n",
      "Testing Accuracy :  0.9768000245094299\n"
     ]
    }
   ],
   "source": [
    "# Architecture:\n",
    "# Input layer with 784 nodes\n",
    "# 1st hidden layer with 700 nodes and activation function = relu\n",
    "# 2nd hidden layer with 700 nodes and activation function = relu\n",
    "# Output layer with 10 nodes and activation function = softmax\n",
    "\n",
    "\n",
    "\n",
    "train_accuracy,test_accuracy = nn2(700,700,\"relu\",\"relu\",\"softmax\")\n",
    "print(\"Training Accuracy : \",train_accuracy)\n",
    "print(\"Testing Accuracy : \",test_accuracy)\n",
    "d=d.append(pd.DataFrame({\"nodes in H1\":[700],\"Activation func of H1\":[\"relu\"],\"nodes in H2\":[700],\"Activation func of H2\":[\"relu\"],\"Activation func of output layer\":[\"softmax\"],'Training Accuracy':[train_accuracy],'Testing Accuracy':[test_accuracy]} ,index=[di]))\n",
    "di=di+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITJ\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 2.3034 - accuracy: 0.1131\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 2.2907 - accuracy: 0.1289\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 2.2674 - accuracy: 0.1785\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 2.2216 - accuracy: 0.1861\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 2.1590 - accuracy: 0.2001\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 2.0931 - accuracy: 0.2398\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 2.0330 - accuracy: 0.2594\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 1.9823 - accuracy: 0.2755\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 1.9407 - accuracy: 0.2784\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 1.9069 - accuracy: 0.2792\n",
      "60000/60000 [==============================] - 2s 35us/step\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "Training Accuracy :  0.2799333333969116\n",
      "Testing Accuracy :  0.27639999985694885\n"
     ]
    }
   ],
   "source": [
    "# Architecture:\n",
    "# Input layer with 784 nodes\n",
    "# only one hidden layer with 1 node and activation function = sigmoid\n",
    "# Output layer with 10 nodes and activation function = softmax\n",
    "\n",
    "\n",
    "\n",
    "train_accuracy,test_accuracy = nn1(1,\"sigmoid\",\"softmax\")\n",
    "print(\"Training Accuracy : \",train_accuracy)\n",
    "print(\"Testing Accuracy : \",test_accuracy)\n",
    "d=d.append(pd.DataFrame({\"nodes in H1\":[1],\"Activation func of H1\":[\"sigmoid\"],\"nodes in H2\":[0],\"Activation func of H2\":[\"\"],\"Activation func of output layer\":[\"softmax\"],'Training Accuracy':[train_accuracy],'Testing Accuracy':[test_accuracy]} ,index=[di]))\n",
    "di=di+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITJ\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 2.3017 - accuracy: 0.1123\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 2.3013 - accuracy: 0.1124\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 2.3013 - accuracy: 0.1124\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 2.3013 - accuracy: 0.1124\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 2.3013 - accuracy: 0.1124\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 2.3013 - accuracy: 0.1124\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 2.3013 - accuracy: 0.1124\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 2.3013 - accuracy: 0.1124\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 2.3013 - accuracy: 0.1124\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 2.3013 - accuracy: 0.1124\n",
      "60000/60000 [==============================] - 2s 39us/step\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "Training Accuracy :  0.11236666887998581\n",
      "Testing Accuracy :  0.11349999904632568\n"
     ]
    }
   ],
   "source": [
    "# Architecture:\n",
    "# Input layer with 784 nodes\n",
    "# 1st hidden layer with 1 nodes and activation function = sigmoid\n",
    "# 2nd hidden layer with 1 nodes and activation function = relu\n",
    "# Output layer with 10 nodes and activation function = softmax\n",
    "\n",
    "\n",
    "\n",
    "train_accuracy,test_accuracy = nn2(1,1,\"sigmoid\",\"relu\",\"softmax\")\n",
    "print(\"Training Accuracy : \",train_accuracy)\n",
    "print(\"Testing Accuracy : \",test_accuracy)\n",
    "d=d.append(pd.DataFrame({\"nodes in H1\":[1],\"Activation func of H1\":[\"sigmoid\"],\"nodes in H2\":[1],\"Activation func of H2\":[\"relu\"],\"Activation func of output layer\":[\"softmax\"],'Training Accuracy':[train_accuracy],'Testing Accuracy':[test_accuracy]} ,index=[di]))\n",
    "di=di+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITJ\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 2.2165 - accuracy: 0.1919\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 1.8461 - accuracy: 0.3420\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 1.5500 - accuracy: 0.4515\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 1.3866 - accuracy: 0.5059\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 1.2878 - accuracy: 0.5298\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 1.2219 - accuracy: 0.5567\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 1.1728 - accuracy: 0.5797\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 1.1351 - accuracy: 0.5946\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 1.1044 - accuracy: 0.6076\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 1.0787 - accuracy: 0.6211\n",
      "60000/60000 [==============================] - 3s 52us/step\n",
      "10000/10000 [==============================] - 0s 48us/step\n",
      "Training Accuracy :  0.626966655254364\n",
      "Testing Accuracy :  0.6327999830245972\n"
     ]
    }
   ],
   "source": [
    "# Architecture:\n",
    "# Input layer with 784 nodes\n",
    "# 1st hidden layer with 50 nodes and activation function = sigmoid\n",
    "# 2nd hidden layer with 5 nodes and activation function = relu\n",
    "# Output layer with 10 nodes and activation function = softmax\n",
    "\n",
    "\n",
    "\n",
    "train_accuracy,test_accuracy = nn2(50,5,\"sigmoid\",\"relu\",\"softmax\")\n",
    "print(\"Training Accuracy : \",train_accuracy)\n",
    "print(\"Testing Accuracy : \",test_accuracy)\n",
    "d=d.append(pd.DataFrame({\"nodes in H1\":[50],\"Activation func of H1\":[\"sigmoid\"],\"nodes in H2\":[5],\"Activation func of H2\":[\"relu\"],\"Activation func of output layer\":[\"softmax\"],'Training Accuracy':[train_accuracy],'Testing Accuracy':[test_accuracy]} ,index=[di]))\n",
    "di=di+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITJ\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 1.8774 - accuracy: 0.3983\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.7844 - accuracy: 0.7728\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.5357 - accuracy: 0.83970s - loss: 0.5396 - \n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.4511 - accuracy: 0.86640s - loss: 0.4553 -  - ETA: 0s - loss: 0.4515 - accura\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.4107 - accuracy: 0.8789\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 8s 125us/step - loss: 0.3790 - accuracy: 0.8887\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 0.3638 - accuracy: 0.8935\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 0.3478 - accuracy: 0.8998\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.3370 - accuracy: 0.9018\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 8s 125us/step - loss: 0.3288 - accuracy: 0.9039\n",
      "60000/60000 [==============================] - 5s 84us/step\n",
      "10000/10000 [==============================] - 1s 70us/step\n",
      "Training Accuracy :  0.9046000242233276\n",
      "Testing Accuracy :  0.9093999862670898\n"
     ]
    }
   ],
   "source": [
    "# Architecture:\n",
    "# Input layer with 784 nodes\n",
    "# 1st hidden layer with 400 nodes and activation function = sigmoid\n",
    "# 2nd hidden layer with 100 nodes and activation function = relu\n",
    "# Output layer with 10 nodes and activation function = softmax\n",
    "\n",
    "\n",
    "\n",
    "train_accuracy,test_accuracy = nn2(400,100,\"sigmoid\",\"relu\",\"softmax\")\n",
    "print(\"Training Accuracy : \",train_accuracy)\n",
    "print(\"Testing Accuracy : \",test_accuracy)\n",
    "d=d.append(pd.DataFrame({\"nodes in H1\":[400],\"Activation func of H1\":[\"sigmoid\"],\"nodes in H2\":[10],\"Activation func of H2\":[\"relu\"],\"Activation func of output layer\":[\"softmax\"],'Training Accuracy':[train_accuracy],'Testing Accuracy':[test_accuracy]} ,index=[di]))\n",
    "di=di+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITJ\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 17s 281us/step - loss: 1.8940 - accuracy: 0.3280\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 17s 275us/step - loss: 0.8073 - accuracy: 0.7260\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 17s 276us/step - loss: 0.5828 - accuracy: 0.8173\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 17s 276us/step - loss: 0.4803 - accuracy: 0.8551\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 16s 275us/step - loss: 0.4315 - accuracy: 0.8704\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 16s 275us/step - loss: 0.4010 - accuracy: 0.8807\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 16s 273us/step - loss: 0.3808 - accuracy: 0.8870\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 16s 274us/step - loss: 0.3663 - accuracy: 0.8910\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 17s 280us/step - loss: 0.3492 - accuracy: 0.8964\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 17s 277us/step - loss: 0.3436 - accuracy: 0.8971\n",
      "60000/60000 [==============================] - 10s 162us/step\n",
      "10000/10000 [==============================] - 2s 161us/step\n",
      "Training Accuracy :  0.9023500084877014\n",
      "Testing Accuracy :  0.9035000205039978\n"
     ]
    }
   ],
   "source": [
    "# Architecture:\n",
    "# Input layer with 784 nodes\n",
    "# 1st hidden layer with 700 nodes and activation function = sigmoid\n",
    "# 2nd hidden layer with 700 nodes and activation function = relu\n",
    "# Output layer with 10 nodes and activation function = softmax\n",
    "\n",
    "\n",
    "\n",
    "train_accuracy,test_accuracy = nn2(700,700,\"sigmoid\",\"relu\",\"softmax\")\n",
    "print(\"Training Accuracy : \",train_accuracy)\n",
    "print(\"Testing Accuracy : \",test_accuracy)\n",
    "d=d.append(pd.DataFrame({\"nodes in H1\":[700],\"Activation func of H1\":[\"sigmoid\"],\"nodes in H2\":[700],\"Activation func of H2\":[\"relu\"],\"Activation func of output layer\":[\"softmax\"],'Training Accuracy':[train_accuracy],'Testing Accuracy':[test_accuracy]} ,index=[di]))\n",
    "di=di+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITJ\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 2.2920 - accuracy: 0.1510\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 2.0251 - accuracy: 0.4218\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 1.5866 - accuracy: 0.5421\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 1.3753 - accuracy: 0.5961\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 1.2555 - accuracy: 0.6249\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 1.1650 - accuracy: 0.6507\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 1.0860 - accuracy: 0.6744\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 1.0132 - accuracy: 0.6930\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.9487 - accuracy: 0.7107\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.8930 - accuracy: 0.7269\n",
      "60000/60000 [==============================] - 3s 54us/step\n",
      "10000/10000 [==============================] - 0s 48us/step\n",
      "Training Accuracy :  0.7334166765213013\n",
      "Testing Accuracy :  0.7329999804496765\n"
     ]
    }
   ],
   "source": [
    "# Architecture:\n",
    "# Input layer with 784 nodes\n",
    "# 1st hidden layer with 50 nodes and activation function = sigmoid\n",
    "# 2nd hidden layer with 5 nodes and activation function = sigmoid\n",
    "# Output layer with 10 nodes and activation function = softmax\n",
    "\n",
    "\n",
    "\n",
    "train_accuracy,test_accuracy = nn2(50,5,\"sigmoid\",\"sigmoid\",\"softmax\")\n",
    "print(\"Training Accuracy : \",train_accuracy)\n",
    "print(\"Testing Accuracy : \",test_accuracy)\n",
    "d=d.append(pd.DataFrame({\"nodes in H1\":[50],\"Activation func of H1\":[\"sigmoid\"],\"nodes in H2\":[5],\"Activation func of H2\":[\"sigmoid\"],\"Activation func of output layer\":[\"softmax\"],'Training Accuracy':[train_accuracy],'Testing Accuracy':[test_accuracy]} ,index=[di]))\n",
    "di=di+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITJ\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 2.0777 - accuracy: 0.2941\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.9735 - accuracy: 0.7168\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.5945 - accuracy: 0.8311\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.4634 - accuracy: 0.86410s - loss: 0.4659 - \n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.4097 - accuracy: 0.8794\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.3771 - accuracy: 0.8887\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.3600 - accuracy: 0.8936\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.3425 - accuracy: 0.89920s - l\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.3296 - accuracy: 0.90300s - loss: 0\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.3173 - accuracy: 0.9067\n",
      "60000/60000 [==============================] - 4s 73us/step\n",
      "10000/10000 [==============================] - 1s 74us/step\n",
      "Training Accuracy :  0.9070666432380676\n",
      "Testing Accuracy :  0.90829998254776\n"
     ]
    }
   ],
   "source": [
    "# Architecture:\n",
    "# Input layer with 784 nodes\n",
    "# 1st hidden layer with 400 nodes and activation function = sigmoid\n",
    "# 2nd hidden layer with 100 nodes and activation function = sigmoid\n",
    "# Output layer with 10 nodes and activation function = softmax\n",
    "\n",
    "\n",
    "\n",
    "train_accuracy,test_accuracy = nn2(400,100,\"sigmoid\",\"sigmoid\",\"softmax\")\n",
    "print(\"Training Accuracy : \",train_accuracy)\n",
    "print(\"Testing Accuracy : \",test_accuracy)\n",
    "d=d.append(pd.DataFrame({\"nodes in H1\":[400],\"Activation func of H1\":[\"sigmoid\"],\"nodes in H2\":[100],\"Activation func of H2\":[\"sigmoid\"],\"Activation func of output layer\":[\"softmax\"],'Training Accuracy':[train_accuracy],'Testing Accuracy':[test_accuracy]} ,index=[di]))\n",
    "di=di+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITJ\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 1.7313 - accuracy: 0.4077\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 1.1220 - accuracy: 0.5987\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.9756 - accuracy: 0.6622\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.8758 - accuracy: 0.7090\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.8020 - accuracy: 0.7417\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.7413 - accuracy: 0.7686\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.6908 - accuracy: 0.7896\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.6491 - accuracy: 0.8069\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.6142 - accuracy: 0.8205\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.5847 - accuracy: 0.8307\n",
      "60000/60000 [==============================] - 3s 53us/step\n",
      "10000/10000 [==============================] - 1s 60us/step\n",
      "Training Accuracy :  0.8356666564941406\n",
      "Testing Accuracy :  0.8353000283241272\n"
     ]
    }
   ],
   "source": [
    "# Architecture:\n",
    "# Input layer with 784 nodes\n",
    "# 1st hidden layer with 50 nodes and activation function = relu\n",
    "# 2nd hidden layer with 5 nodes and activation function = relu\n",
    "# Output layer with 10 nodes and activation function = softmax\n",
    "\n",
    "\n",
    "\n",
    "train_accuracy,test_accuracy = nn2(50,5,\"relu\",\"relu\",\"softmax\")\n",
    "print(\"Training Accuracy : \",train_accuracy)\n",
    "print(\"Testing Accuracy : \",test_accuracy)\n",
    "d=d.append(pd.DataFrame({\"nodes in H1\":[50],\"Activation func of H1\":[\"relu\"],\"nodes in H2\":[5],\"Activation func of H2\":[\"relu\"],\"Activation func of output layer\":[\"softmax\"],'Training Accuracy':[train_accuracy],'Testing Accuracy':[test_accuracy]} ,index=[di]))\n",
    "di=di+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITJ\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.6686 - accuracy: 0.8221\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.3046 - accuracy: 0.9119\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.2532 - accuracy: 0.9259\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 0.2131 - accuracy: 0.9380\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.1805 - accuracy: 0.9478\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 0.1535 - accuracy: 0.9552\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.1326 - accuracy: 0.9607\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.1150 - accuracy: 0.9668\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.0997 - accuracy: 0.9710\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.0885 - accuracy: 0.9742\n",
      "60000/60000 [==============================] - 6s 93us/step\n",
      "10000/10000 [==============================] - 1s 93us/step\n",
      "Training Accuracy :  0.9775999784469604\n",
      "Testing Accuracy :  0.9699000120162964\n"
     ]
    }
   ],
   "source": [
    "# Architecture:\n",
    "# Input layer with 784 nodes\n",
    "# 1st hidden layer with 400 nodes and activation function = relu\n",
    "# 2nd hidden layer with 100 nodes and activation function = relu\n",
    "# Output layer with 10 nodes and activation function = softmax\n",
    "\n",
    "\n",
    "\n",
    "train_accuracy,test_accuracy = nn2(400,100,\"relu\",\"relu\",\"softmax\")\n",
    "print(\"Training Accuracy : \",train_accuracy)\n",
    "print(\"Testing Accuracy : \",test_accuracy)\n",
    "d=d.append(pd.DataFrame({\"nodes in H1\":[400],\"Activation func of H1\":[\"relu\"],\"nodes in H2\":[100],\"Activation func of H2\":[\"relu\"],\"Activation func of output layer\":[\"softmax\"],'Training Accuracy':[train_accuracy],'Testing Accuracy':[test_accuracy]} ,index=[di]))\n",
    "di=di+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITJ\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 2.3013 - accuracy: 0.1095\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 2.2677 - accuracy: 0.1557\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 2.0462 - accuracy: 0.2104\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 75us/step - loss: 1.8869 - accuracy: 0.2316\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 1.8322 - accuracy: 0.2452\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 1.8038 - accuracy: 0.2516\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 1.7840 - accuracy: 0.2563\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 1.7684 - accuracy: 0.2623\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 1.7548 - accuracy: 0.2642\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 1.7419 - accuracy: 0.2705\n",
      "60000/60000 [==============================] - 3s 57us/step\n",
      "10000/10000 [==============================] - ETA:  - 1s 60us/step\n",
      "Training Accuracy :  0.2781499922275543\n",
      "Testing Accuracy :  0.2718999981880188\n"
     ]
    }
   ],
   "source": [
    "# Architecture:\n",
    "# Input layer with 784 nodes\n",
    "# 1st hidden layer with 50 nodes and activation function = softmax\n",
    "# 2nd hidden layer with 5 nodes and activation function = softmax\n",
    "# Output layer with 10 nodes and activation function = softmax\n",
    "\n",
    "\n",
    "\n",
    "train_accuracy,test_accuracy = nn2(50,5,\"softmax\",\"softmax\",\"softmax\")\n",
    "print(\"Training Accuracy : \",train_accuracy)\n",
    "print(\"Testing Accuracy : \",test_accuracy)\n",
    "d=d.append(pd.DataFrame({\"nodes in H1\":[50],\"Activation func of H1\":[\"softmax\"],\"nodes in H2\":[5],\"Activation func of H2\":[\"softmax\"],\"Activation func of output layer\":[\"softmax\"],'Training Accuracy':[train_accuracy],'Testing Accuracy':[test_accuracy]} ,index=[di]))\n",
    "di=di+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITJ\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 2.3016 - accuracy: 0.11130s - loss: 2.3016 - accuracy: \n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 7s 125us/step - loss: 2.3014 - accuracy: 0.1124\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 2.3014 - accuracy: 0.11240s - loss: 2\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 2.3014 - accuracy: 0.1124\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 2.3013 - accuracy: 0.1124\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 2.3013 - accuracy: 0.1124\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 2.2963 - accuracy: 0.1265\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 2.0266 - accuracy: 0.2154\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 1.8222 - accuracy: 0.2481 - ETA: 3s - loss: - ETA: 3s - loss: 1.8343 - accu - ETA - ETA: 0s - loss: 1.8234 - \n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 1.7789 - accuracy: 0.27901s - loss: 1.7824 - accu - E\n",
      "60000/60000 [==============================] - 4s 73us/step\n",
      "10000/10000 [==============================] - 1s 69us/step\n",
      "Training Accuracy :  0.27273333072662354\n",
      "Testing Accuracy :  0.26489999890327454\n"
     ]
    }
   ],
   "source": [
    "# Architecture:\n",
    "# Input layer with 784 nodes\n",
    "# 1st hidden layer with 400 nodes and activation function = softmax\n",
    "# 2nd hidden layer with 100 nodes and activation function = softmax\n",
    "# Output layer with 10 nodes and activation function = softmax\n",
    "\n",
    "\n",
    "\n",
    "train_accuracy,test_accuracy = nn2(400,100,\"softmax\",\"softmax\",\"softmax\")\n",
    "print(\"Training Accuracy : \",train_accuracy)\n",
    "print(\"Testing Accuracy : \",test_accuracy)\n",
    "d=d.append(pd.DataFrame({\"nodes in H1\":[400],\"Activation func of H1\":[\"softmax\"],\"nodes in H2\":[100],\"Activation func of H2\":[\"softmax\"],\"Activation func of output layer\":[\"softmax\"],'Training Accuracy':[train_accuracy],'Testing Accuracy':[test_accuracy]} ,index=[di]))\n",
    "di=di+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.DataFrame(columns = ['Classification','Training Accuracy', 'Testing Accuracy']) \n",
    "ti=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITJ\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\NITJ\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier=LogisticRegression()\n",
    "classifier.fit(X_train,y_train)\n",
    "train_accuracy=classifier.score(X_train,y_train)\n",
    "test_accuracy=classifier.score(X_test,y_test)\n",
    "t=t.append(pd.DataFrame({\"Classification\":[\"LogisticRegression\"],'Training Accuracy':[train_accuracy],'Testing Accuracy':[test_accuracy]} ,index=[ti]))\n",
    "ti=ti+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITJ\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier5 = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier5.fit(X_train, y_train)\n",
    "train_accuracy=classifier5.score(X_train,y_train)\n",
    "test_accuracy=classifier5.score(X_test,y_test)\n",
    "t=t.append(pd.DataFrame({\"Classification\":[\"Support Vector\"],'Training Accuracy':[train_accuracy],'Testing Accuracy':[test_accuracy]} ,index=[ti]))\n",
    "ti=ti+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier2 = GaussianNB()\n",
    "classifier2.fit(X_train,y_train)\n",
    "train_accuracy=classifier2.score(X_train,y_train)\n",
    "test_accuracy=classifier2.score(X_test,y_test)\n",
    "t=t.append(pd.DataFrame({\"Classification\":[\"Naive Bayes\"],'Training Accuracy':[train_accuracy],'Testing Accuracy':[test_accuracy]} ,index=[ti]))\n",
    "ti=ti+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Decision Tree Classification to the Training set\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier3 = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "classifier3.fit(X_train,y_train)\n",
    "train_accuracy=classifier3.score(X_train,y_train)\n",
    "test_accuracy=classifier3.score(X_test,y_test)\n",
    "t=t.append(pd.DataFrame({\"Classification\":[\"Decision Tree\"],'Training Accuracy':[train_accuracy],'Testing Accuracy':[test_accuracy]} ,index=[ti]))\n",
    "ti=ti+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5649"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nodes in H1</th>\n",
       "      <th>Activation func of H1</th>\n",
       "      <th>nodes in H2</th>\n",
       "      <th>Activation func of H2</th>\n",
       "      <th>Activation func of output layer</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.264083</td>\n",
       "      <td>0.2623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.257333</td>\n",
       "      <td>0.2577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>5</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.688583</td>\n",
       "      <td>0.7008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>400</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.910317</td>\n",
       "      <td>0.9099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>700</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>700</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.882750</td>\n",
       "      <td>0.8873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>relu</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.112367</td>\n",
       "      <td>0.1135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>relu</td>\n",
       "      <td>1</td>\n",
       "      <td>relu</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.112367</td>\n",
       "      <td>0.1135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>5</td>\n",
       "      <td>relu</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.881367</td>\n",
       "      <td>0.8849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>400</td>\n",
       "      <td>relu</td>\n",
       "      <td>100</td>\n",
       "      <td>relu</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.965650</td>\n",
       "      <td>0.9613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>700</td>\n",
       "      <td>relu</td>\n",
       "      <td>700</td>\n",
       "      <td>relu</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.989733</td>\n",
       "      <td>0.9780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>relu</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>relu</td>\n",
       "      <td>0.098717</td>\n",
       "      <td>0.0980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>relu</td>\n",
       "      <td>1</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.098717</td>\n",
       "      <td>0.0980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>5</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.098717</td>\n",
       "      <td>0.0980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>400</td>\n",
       "      <td>relu</td>\n",
       "      <td>100</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.098717</td>\n",
       "      <td>0.0980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>700</td>\n",
       "      <td>relu</td>\n",
       "      <td>700</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.098717</td>\n",
       "      <td>0.0980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>relu</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.112367</td>\n",
       "      <td>0.1135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>relu</td>\n",
       "      <td>1</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.338517</td>\n",
       "      <td>0.3390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>5</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.877033</td>\n",
       "      <td>0.8742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>400</td>\n",
       "      <td>relu</td>\n",
       "      <td>100</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.977833</td>\n",
       "      <td>0.9704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>700</td>\n",
       "      <td>relu</td>\n",
       "      <td>700</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.9768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.279933</td>\n",
       "      <td>0.2764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.112367</td>\n",
       "      <td>0.1135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>50</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>5</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.626967</td>\n",
       "      <td>0.6328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>400</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>10</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.904600</td>\n",
       "      <td>0.9094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>700</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>700</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.902350</td>\n",
       "      <td>0.9035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>50</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>5</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.733417</td>\n",
       "      <td>0.7330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>400</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.907067</td>\n",
       "      <td>0.9083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>5</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.835667</td>\n",
       "      <td>0.8353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>400</td>\n",
       "      <td>relu</td>\n",
       "      <td>100</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.977600</td>\n",
       "      <td>0.9699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>softmax</td>\n",
       "      <td>5</td>\n",
       "      <td>softmax</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.278150</td>\n",
       "      <td>0.2719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>400</td>\n",
       "      <td>softmax</td>\n",
       "      <td>100</td>\n",
       "      <td>softmax</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.272733</td>\n",
       "      <td>0.2649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nodes in H1 Activation func of H1 nodes in H2 Activation func of H2  \\\n",
       "1            1               sigmoid           0                         \n",
       "2            1               sigmoid           1               sigmoid   \n",
       "3           50               sigmoid           5               sigmoid   \n",
       "4          400               sigmoid         100               sigmoid   \n",
       "5          700               sigmoid         700               sigmoid   \n",
       "6            1                  relu           0                         \n",
       "7            1                  relu           1                  relu   \n",
       "8           50                  relu           5                  relu   \n",
       "9          400                  relu         100                  relu   \n",
       "10         700                  relu         700                  relu   \n",
       "11           1                  relu           0                         \n",
       "12           1                  relu           1                  relu   \n",
       "13          50                  relu           5                  relu   \n",
       "14         400                  relu         100                  relu   \n",
       "15         700                  relu         700                  relu   \n",
       "16           1                  relu           0                         \n",
       "17           1                  relu           1                  relu   \n",
       "18          50                  relu           5                  relu   \n",
       "19         400                  relu         100                  relu   \n",
       "20         700                  relu         700                  relu   \n",
       "21           1               sigmoid           0                         \n",
       "22           1               sigmoid           1                  relu   \n",
       "23          50               sigmoid           5                  relu   \n",
       "24         400               sigmoid          10                  relu   \n",
       "25         700               sigmoid         700                  relu   \n",
       "26          50               sigmoid           5               sigmoid   \n",
       "27         400               sigmoid         100               sigmoid   \n",
       "28          50                  relu           5                  relu   \n",
       "29         400                  relu         100                  relu   \n",
       "30          50               softmax           5               softmax   \n",
       "31         400               softmax         100               softmax   \n",
       "\n",
       "   Activation func of output layer  Training Accuracy  Testing Accuracy  \n",
       "1                          sigmoid           0.264083            0.2623  \n",
       "2                          sigmoid           0.257333            0.2577  \n",
       "3                          sigmoid           0.688583            0.7008  \n",
       "4                          sigmoid           0.910317            0.9099  \n",
       "5                          sigmoid           0.882750            0.8873  \n",
       "6                          sigmoid           0.112367            0.1135  \n",
       "7                          sigmoid           0.112367            0.1135  \n",
       "8                          sigmoid           0.881367            0.8849  \n",
       "9                          sigmoid           0.965650            0.9613  \n",
       "10                         sigmoid           0.989733            0.9780  \n",
       "11                            relu           0.098717            0.0980  \n",
       "12                            relu           0.098717            0.0980  \n",
       "13                            relu           0.098717            0.0980  \n",
       "14                            relu           0.098717            0.0980  \n",
       "15                            relu           0.098717            0.0980  \n",
       "16                         softmax           0.112367            0.1135  \n",
       "17                         softmax           0.338517            0.3390  \n",
       "18                         softmax           0.877033            0.8742  \n",
       "19                         softmax           0.977833            0.9704  \n",
       "20                         softmax           0.989583            0.9768  \n",
       "21                         softmax           0.279933            0.2764  \n",
       "22                         softmax           0.112367            0.1135  \n",
       "23                         softmax           0.626967            0.6328  \n",
       "24                         softmax           0.904600            0.9094  \n",
       "25                         softmax           0.902350            0.9035  \n",
       "26                         softmax           0.733417            0.7330  \n",
       "27                         softmax           0.907067            0.9083  \n",
       "28                         softmax           0.835667            0.8353  \n",
       "29                         softmax           0.977600            0.9699  \n",
       "30                         softmax           0.278150            0.2719  \n",
       "31                         softmax           0.272733            0.2649  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.837983</td>\n",
       "      <td>0.8478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.564900</td>\n",
       "      <td>0.5558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.8863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Classification  Training Accuracy  Testing Accuracy\n",
       "1  LogisticRegression           0.837983            0.8478\n",
       "2         Naive Bayes           0.564900            0.5558\n",
       "3       Decision Tree           1.000000            0.8863"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Traditional classification Techniques\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
